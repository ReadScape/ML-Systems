{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>language</th>\n",
       "      <th>release_date</th>\n",
       "      <th>latest_update</th>\n",
       "      <th>tags</th>\n",
       "      <th>genres</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kejahatan Cinta</td>\n",
       "      <td>Seorang detektif swasta, Anya, sedang menyelid...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>detektif,pembunuhan,misteri,cinta,romansa</td>\n",
       "      <td>romansa,misteri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Raja Terakhir</td>\n",
       "      <td>Di dunia yang dikuasai oleh iblis, seorang pem...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>fantasi,aksi,petualangan,pertarungan,kekuatan</td>\n",
       "      <td>fantasi,aksi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fiction_id            title  \\\n",
       "0           1  Kejahatan Cinta   \n",
       "1           2    Raja Terakhir   \n",
       "\n",
       "                                            overview   language release_date  \\\n",
       "0  Seorang detektif swasta, Anya, sedang menyelid...  Indonesia   2023-10-01   \n",
       "1  Di dunia yang dikuasai oleh iblis, seorang pem...  Indonesia   2023-10-02   \n",
       "\n",
       "  latest_update                                           tags  \\\n",
       "0    2023-10-06      detektif,pembunuhan,misteri,cinta,romansa   \n",
       "1    2023-10-02  fantasi,aksi,petualangan,pertarungan,kekuatan   \n",
       "\n",
       "            genres  chapter  \n",
       "0  romansa,misteri        2  \n",
       "1     fantasi,aksi        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/fiction dataset - Sheet1.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  fiction_id  rating\n",
       "0       29          39       0\n",
       "1       17          44       4\n",
       "2       94          59       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data rating\n",
    "r_df = pd.read_csv('Dataset/Rating Dataset - Sheet1.csv')\n",
    "rating_data = r_df[['user_id', 'fiction_id', 'rating']]\n",
    "rating_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangeran yang Tertukar</td>\n",
       "      <td>romansa,petualangan,aksi</td>\n",
       "      <td>Seorang gadis muda menemukan pangeran yang ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Pangeran yang Tertukar</td>\n",
       "      <td>romansa,petualangan,aksi</td>\n",
       "      <td>Seorang gadis muda menemukan pangeran yang ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>Pangeran yang Tertukar</td>\n",
       "      <td>romansa,petualangan,aksi</td>\n",
       "      <td>Seorang gadis muda menemukan pangeran yang ter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  fiction_id  rating                   title  \\\n",
       "0       29          39       0  Pangeran yang Tertukar   \n",
       "1      100          39       1  Pangeran yang Tertukar   \n",
       "2       45          39       2  Pangeran yang Tertukar   \n",
       "\n",
       "                     genres                                           overview  \n",
       "0  romansa,petualangan,aksi  Seorang gadis muda menemukan pangeran yang ter...  \n",
       "1  romansa,petualangan,aksi  Seorang gadis muda menemukan pangeran yang ter...  \n",
       "2  romansa,petualangan,aksi  Seorang gadis muda menemukan pangeran yang ter...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data = rating_data.merge(df[['fiction_id', 'title', 'genres', 'overview']], left_on='fiction_id', right_on='fiction_id')\n",
    "rating_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kejahatan Cinta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Raja Terakhir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fiction_id            title\n",
       "0           1  Kejahatan Cinta\n",
       "1           2    Raja Terakhir"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fanfic_df = df[['fiction_id', 'title']]\n",
    "fanfic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data['user_id'] = rating_data['user_id'].astype(str)\n",
    "\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(rating_data[['user_id', 'title', 'rating']]))\n",
    "fanfics = tf.data.Dataset.from_tensor_slices(dict(fanfic_df[['title']]))\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    'title': x['title'],\n",
    "    'user_id': x['user_id'],\n",
    "    'rating': float(x['rating'])\n",
    "})\n",
    "\n",
    "fanfics = fanfics.map(lambda x: x['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 5027\n"
     ]
    }
   ],
   "source": [
    "print('Total Data: {}'.format(len(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(5_027, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = ratings.take(2_500)\n",
    "test = ratings.skip(2_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fanfic_titles = fanfics.batch(50)\n",
    "user_ids = ratings.batch(50).map(lambda x: x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Fanfic: 99\n",
      "Unique users: 100\n"
     ]
    }
   ],
   "source": [
    "unique_fanfics_titles = np.unique(np.concatenate(list(fanfic_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "print('Unique Fanfic: {}'.format(len(unique_fanfics_titles)))\n",
    "print('Unique users: {}'.format(len(unique_user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FanficsModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 64\n",
    "\n",
    "    # User and fanfic models.\n",
    "    self.fanfic_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_fanfics_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_fanfics_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=fanfics.batch(128).map(self.fanfic_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features['user_id'])\n",
    "    # And pick out the fanfic features and pass them into the fanfic model.\n",
    "    fanfic_embeddings = self.fanfic_model(features['title'])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        fanfic_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and fanfic embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, fanfic_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop('rating')\n",
    "\n",
    "    user_embeddings, fanfic_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, fanfic_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 7s 95ms/step - mean_absolute_error: 1.5719 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0128 - factorized_top_k/top_10_categorical_accuracy: 0.0552 - factorized_top_k/top_50_categorical_accuracy: 0.3540 - factorized_top_k/top_100_categorical_accuracy: 0.9816 - loss: 199.4725 - regularization_loss: 0.0000e+00 - total_loss: 199.4725\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 5s 94ms/step - mean_absolute_error: 1.5222 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0336 - factorized_top_k/top_10_categorical_accuracy: 0.1220 - factorized_top_k/top_50_categorical_accuracy: 0.4664 - factorized_top_k/top_100_categorical_accuracy: 0.9912 - loss: 198.8847 - regularization_loss: 0.0000e+00 - total_loss: 198.8847\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 5s 92ms/step - mean_absolute_error: 1.5101 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0516 - factorized_top_k/top_10_categorical_accuracy: 0.1708 - factorized_top_k/top_50_categorical_accuracy: 0.5816 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 197.6903 - regularization_loss: 0.0000e+00 - total_loss: 197.6903\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 5s 91ms/step - mean_absolute_error: 1.4940 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0656 - factorized_top_k/top_10_categorical_accuracy: 0.2012 - factorized_top_k/top_50_categorical_accuracy: 0.6688 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 195.5141 - regularization_loss: 0.0000e+00 - total_loss: 195.5141\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 4s 88ms/step - mean_absolute_error: 1.4737 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0780 - factorized_top_k/top_10_categorical_accuracy: 0.2232 - factorized_top_k/top_50_categorical_accuracy: 0.7324 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 193.0428 - regularization_loss: 0.0000e+00 - total_loss: 193.0428\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 5s 91ms/step - mean_absolute_error: 1.4461 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0892 - factorized_top_k/top_10_categorical_accuracy: 0.2324 - factorized_top_k/top_50_categorical_accuracy: 0.7820 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 190.7233 - regularization_loss: 0.0000e+00 - total_loss: 190.7233\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 4s 89ms/step - mean_absolute_error: 1.4113 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0928 - factorized_top_k/top_10_categorical_accuracy: 0.2412 - factorized_top_k/top_50_categorical_accuracy: 0.8208 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 188.6724 - regularization_loss: 0.0000e+00 - total_loss: 188.6724\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 4s 89ms/step - mean_absolute_error: 1.3684 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0932 - factorized_top_k/top_10_categorical_accuracy: 0.2516 - factorized_top_k/top_50_categorical_accuracy: 0.8556 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 186.8727 - regularization_loss: 0.0000e+00 - total_loss: 186.8727\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 5s 99ms/step - mean_absolute_error: 1.3199 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0964 - factorized_top_k/top_10_categorical_accuracy: 0.2548 - factorized_top_k/top_50_categorical_accuracy: 0.8804 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 185.2828 - regularization_loss: 0.0000e+00 - total_loss: 185.2828\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 4s 89ms/step - mean_absolute_error: 1.2680 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0952 - factorized_top_k/top_10_categorical_accuracy: 0.2552 - factorized_top_k/top_50_categorical_accuracy: 0.8976 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 183.8643 - regularization_loss: 0.0000e+00 - total_loss: 183.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x188194ecc10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FanficsModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "cached_train = train.shuffle(5_027).batch(50).cache()\n",
    "cached_test = test.batch(50).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 5s 93ms/step - mean_absolute_error: 1.5539 - factorized_top_k/top_1_categorical_accuracy: 7.9145e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0020 - factorized_top_k/top_10_categorical_accuracy: 0.0024 - factorized_top_k/top_50_categorical_accuracy: 0.4693 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 194.9364 - regularization_loss: 0.0000e+00 - total_loss: 194.9364\n",
      "\n",
      "Retrieval top-5 accuracy: 0.002\n",
      "Ranking MAE: 1.554\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"\\nRetrieval top-5 accuracy: {metrics['factorized_top_k/top_5_categorical_accuracy']:.3f}\")\n",
    "print(f\"Ranking MAE: {metrics['mean_absolute_error']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fanfic(user, top_n=3):\n",
    "    # Create a model that takes in raw query features, and\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    # recommends fanfics out of the entire fanfics dataset.\n",
    "    index.index_from_dataset(\n",
    "      tf.data.Dataset.zip((fanfics.batch(100), fanfics.batch(100).map(model.fanfic_model)))\n",
    "    )\n",
    "\n",
    "    # Get recommendations.\n",
    "    _, titles = index(tf.constant([str(user)]))\n",
    "    \n",
    "    print('Top {} recommendations for user {}:\\n'.format(top_n, user))\n",
    "    for i, title in enumerate(titles[0, :top_n].numpy()):\n",
    "        print('{}. {}'.format(i+1, title.decode(\"utf-8\")))\n",
    "\n",
    "def predict_rating(user, fanfic):\n",
    "    trained_fanfic_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "          \"userId\": np.array([str(user)]),\n",
    "          \"original_title\": np.array([fanfic])\n",
    "      })\n",
    "    print(\"Predicted rating for {}: {}\".format(fanfic, predicted_rating.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 5:\n",
      "\n",
      "1. Cahaya di Dalam Gelap\n",
      "2. Petualangan Mencari Mahkota Suci\n",
      "3. Pangeran yang Tertukar\n",
      "4. Cinta Tak Terduga\n",
      "5. Kembali ke Masa Depan\n"
     ]
    }
   ],
   "source": [
    "predict_fanfic(5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
