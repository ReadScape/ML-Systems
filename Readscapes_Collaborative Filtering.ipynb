{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>language</th>\n",
       "      <th>release_date</th>\n",
       "      <th>latest_update</th>\n",
       "      <th>tags</th>\n",
       "      <th>genres</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kejahatan Cinta</td>\n",
       "      <td>Seorang detektif swasta, Anya, sedang menyelid...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>detektif,pembunuhan,misteri,cinta,romansa</td>\n",
       "      <td>romansa,misteri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Raja Terakhir</td>\n",
       "      <td>Di dunia yang dikuasai oleh iblis, seorang pem...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>fantasi,aksi,petualangan,pertarungan,kekuatan</td>\n",
       "      <td>fantasi,aksi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fiction_id            title  \\\n",
       "0           1  Kejahatan Cinta   \n",
       "1           2    Raja Terakhir   \n",
       "\n",
       "                                            overview   language release_date  \\\n",
       "0  Seorang detektif swasta, Anya, sedang menyelid...  Indonesia   2023-10-01   \n",
       "1  Di dunia yang dikuasai oleh iblis, seorang pem...  Indonesia   2023-10-02   \n",
       "\n",
       "  latest_update                                           tags  \\\n",
       "0    2023-10-06      detektif,pembunuhan,misteri,cinta,romansa   \n",
       "1    2023-10-02  fantasi,aksi,petualangan,pertarungan,kekuatan   \n",
       "\n",
       "            genres  chapter  \n",
       "0  romansa,misteri        2  \n",
       "1     fantasi,aksi        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/fiction dataset - Sheet1.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  fiction_id  rating\n",
       "0       29          39       0\n",
       "1       17          44       4\n",
       "2       94          59       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data rating\n",
    "r_df = pd.read_csv('Dataset/Rating Dataset - Sheet1.csv')\n",
    "rating_data = r_df[['user_id', 'fiction_id', 'rating']]\n",
    "rating_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangeran yang Tertukar</td>\n",
       "      <td>romansa,petualangan,aksi</td>\n",
       "      <td>Seorang gadis muda menemukan pangeran yang ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Pangeran yang Tertukar</td>\n",
       "      <td>romansa,petualangan,aksi</td>\n",
       "      <td>Seorang gadis muda menemukan pangeran yang ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>Pangeran yang Tertukar</td>\n",
       "      <td>romansa,petualangan,aksi</td>\n",
       "      <td>Seorang gadis muda menemukan pangeran yang ter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  fiction_id  rating                   title  \\\n",
       "0       29          39       0  Pangeran yang Tertukar   \n",
       "1      100          39       1  Pangeran yang Tertukar   \n",
       "2       45          39       2  Pangeran yang Tertukar   \n",
       "\n",
       "                     genres                                           overview  \n",
       "0  romansa,petualangan,aksi  Seorang gadis muda menemukan pangeran yang ter...  \n",
       "1  romansa,petualangan,aksi  Seorang gadis muda menemukan pangeran yang ter...  \n",
       "2  romansa,petualangan,aksi  Seorang gadis muda menemukan pangeran yang ter...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data = rating_data.merge(df[['fiction_id', 'title', 'genres', 'overview']], left_on='fiction_id', right_on='fiction_id')\n",
    "rating_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiction_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kejahatan Cinta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Raja Terakhir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fiction_id            title\n",
       "0           1  Kejahatan Cinta\n",
       "1           2    Raja Terakhir"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fanfic_df = df[['fiction_id', 'title']]\n",
    "fanfic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data['user_id'] = rating_data['user_id'].astype(str)\n",
    "\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(rating_data[['user_id', 'title', 'rating']]))\n",
    "fanfics = tf.data.Dataset.from_tensor_slices(dict(fanfic_df[['title']]))\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    'title': x['title'],\n",
    "    'user_id': x['user_id'],\n",
    "    'rating': float(x['rating'])\n",
    "})\n",
    "\n",
    "fanfics = fanfics.map(lambda x: x['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 5027\n"
     ]
    }
   ],
   "source": [
    "print('Total Data: {}'.format(len(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(5027, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = ratings.take(4017)\n",
    "test = ratings.skip(4017).take(1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fanfic_titles = fanfics.batch(16)\n",
    "user_ids = ratings.batch(16).map(lambda x: x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Fanfic: 99\n",
      "Unique users: 100\n"
     ]
    }
   ],
   "source": [
    "unique_fanfics_titles = np.unique(np.concatenate(list(fanfic_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "print('Unique Fanfic: {}'.format(len(unique_fanfics_titles)))\n",
    "print('Unique users: {}'.format(len(unique_user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Ada judul yang sama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FanficsModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # User and fanfic models.\n",
    "    self.fanfic_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_fanfics_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_fanfics_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=fanfics.batch(128).map(self.fanfic_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features['user_id'])\n",
    "    # And pick out the fanfic features and pass them into the fanfic model.\n",
    "    fanfic_embeddings = self.fanfic_model(features['title'])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        fanfic_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and fanfic embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, fanfic_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop('rating')\n",
    "\n",
    "    user_embeddings, fanfic_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, fanfic_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - 10s 63ms/step - mean_absolute_error: 2.3443 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0388 - factorized_top_k/top_10_categorical_accuracy: 0.0884 - factorized_top_k/top_50_categorical_accuracy: 0.4822 - factorized_top_k/top_100_categorical_accuracy: 0.9910 - loss: 58.9992 - regularization_loss: 0.0000e+00 - total_loss: 58.9992\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 61ms/step - mean_absolute_error: 1.9888 - factorized_top_k/top_1_categorical_accuracy: 2.4894e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0383 - factorized_top_k/top_10_categorical_accuracy: 0.0904 - factorized_top_k/top_50_categorical_accuracy: 0.4849 - factorized_top_k/top_100_categorical_accuracy: 0.9908 - loss: 57.9276 - regularization_loss: 0.0000e+00 - total_loss: 57.9276\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 62ms/step - mean_absolute_error: 1.6620 - factorized_top_k/top_1_categorical_accuracy: 2.4894e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0378 - factorized_top_k/top_10_categorical_accuracy: 0.0904 - factorized_top_k/top_50_categorical_accuracy: 0.4864 - factorized_top_k/top_100_categorical_accuracy: 0.9913 - loss: 56.9050 - regularization_loss: 0.0000e+00 - total_loss: 56.9050\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 63ms/step - mean_absolute_error: 1.5230 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0373 - factorized_top_k/top_10_categorical_accuracy: 0.0904 - factorized_top_k/top_50_categorical_accuracy: 0.4884 - factorized_top_k/top_100_categorical_accuracy: 0.9913 - loss: 56.4996 - regularization_loss: 0.0000e+00 - total_loss: 56.4996\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 65ms/step - mean_absolute_error: 1.5211 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0376 - factorized_top_k/top_10_categorical_accuracy: 0.0919 - factorized_top_k/top_50_categorical_accuracy: 0.4889 - factorized_top_k/top_100_categorical_accuracy: 0.9915 - loss: 56.4504 - regularization_loss: 0.0000e+00 - total_loss: 56.4504\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 9s 72ms/step - mean_absolute_error: 1.5205 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0376 - factorized_top_k/top_10_categorical_accuracy: 0.0926 - factorized_top_k/top_50_categorical_accuracy: 0.4914 - factorized_top_k/top_100_categorical_accuracy: 0.9918 - loss: 56.4469 - regularization_loss: 0.0000e+00 - total_loss: 56.4469\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 9s 71ms/step - mean_absolute_error: 1.5201 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0386 - factorized_top_k/top_10_categorical_accuracy: 0.0931 - factorized_top_k/top_50_categorical_accuracy: 0.4932 - factorized_top_k/top_100_categorical_accuracy: 0.9918 - loss: 56.4458 - regularization_loss: 0.0000e+00 - total_loss: 56.4458\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - mean_absolute_error: 1.5198 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0393 - factorized_top_k/top_10_categorical_accuracy: 0.0936 - factorized_top_k/top_50_categorical_accuracy: 0.4954 - factorized_top_k/top_100_categorical_accuracy: 0.9915 - loss: 56.4449 - regularization_loss: 0.0000e+00 - total_loss: 56.4449\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 9s 67ms/step - mean_absolute_error: 1.5194 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0398 - factorized_top_k/top_10_categorical_accuracy: 0.0946 - factorized_top_k/top_50_categorical_accuracy: 0.4984 - factorized_top_k/top_100_categorical_accuracy: 0.9918 - loss: 56.4441 - regularization_loss: 0.0000e+00 - total_loss: 56.4441\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 61ms/step - mean_absolute_error: 1.5191 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0406 - factorized_top_k/top_10_categorical_accuracy: 0.0956 - factorized_top_k/top_50_categorical_accuracy: 0.4991 - factorized_top_k/top_100_categorical_accuracy: 0.9918 - loss: 56.4433 - regularization_loss: 0.0000e+00 - total_loss: 56.4433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15d09653ad0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FanficsModel(rating_weight=0.5, retrieval_weight=0.5)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(1e-3))\n",
    "\n",
    "cached_train = train.shuffle(5027).batch(32).cache()\n",
    "cached_test = test.batch(32).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 89ms/step - mean_absolute_error: 1.4958 - factorized_top_k/top_1_categorical_accuracy: 0.0119 - factorized_top_k/top_5_categorical_accuracy: 0.0525 - factorized_top_k/top_10_categorical_accuracy: 0.1000 - factorized_top_k/top_50_categorical_accuracy: 0.5416 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 55.1183 - regularization_loss: 0.0000e+00 - total_loss: 55.1183\n",
      "\n",
      "Retrieval top-10 accuracy: 0.100\n",
      "Ranking MAE: 1.496\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"\\nRetrieval top-10 accuracy: {metrics['factorized_top_k/top_10_categorical_accuracy']:.3f}\")\n",
    "print(f\"Ranking MAE: {metrics['mean_absolute_error']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fanfic(user, top_n=3):\n",
    "    # Create a model that takes in raw query features, and\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    # recommends fanfics out of the entire fanfics dataset.\n",
    "    index.index_from_dataset(\n",
    "      tf.data.Dataset.zip((fanfics.batch(100), fanfics.batch(100).map(model.fanfic_model)))\n",
    "    )\n",
    "\n",
    "    # Get recommendations.\n",
    "    _, titles = index(tf.constant([str(user)]))\n",
    "    \n",
    "    print('Top {} recommendations for user {}:\\n'.format(top_n, user))\n",
    "    for i, title in enumerate(titles[0, :top_n].numpy()):\n",
    "        print('{}. {}'.format(i+1, title.decode(\"utf-8\")))\n",
    "\n",
    "def predict_rating(user, fanfic):\n",
    "    trained_fanfic_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "          \"userId\": np.array([str(user)]),\n",
    "          \"original_title\": np.array([fanfic])\n",
    "      })\n",
    "    print(\"Predicted rating for {}: {}\".format(fanfic, predicted_rating.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for user 5:\n",
      "\n",
      "1. Perjalanan ke Dunia Bawah\n",
      "2. Detektif Hewan\n",
      "3. Ksatria Tanpa Pedang\n",
      "4. Pangeran yang Tertukar\n",
      "5. Perjuangan Seorang Atlet\n",
      "6. Perjalanan Menembus Dimensi\n",
      "7. Kisah Cinta yang Tak Terlupakan\n",
      "8. Keajaiban Cinta\n",
      "9. Penyelamat Dunia\n",
      "10. Atlantea\n"
     ]
    }
   ],
   "source": [
    "predict_fanfic(5, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
