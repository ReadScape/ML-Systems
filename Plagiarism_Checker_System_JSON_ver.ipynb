{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lWjJMunMSlEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4798b4ec-7d96-4cf0-9add-d785cc69f7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import all necessary library and function\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "#!pip install nltk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the function to remove unnecesary symbols and empty arrays\n",
        "\n",
        "def remove(text):\n",
        "  pattern = r'[“”‘’:;\"?_\\',.()\\–\\[\\]]'\n",
        "  sub_text = re.sub(pattern,'', text)\n",
        "  pattern = r'[\\-\\–]'\n",
        "  sub_text = re.sub(pattern,' ', sub_text)\n",
        "  token_text = word_tokenize(sub_text)\n",
        "  words = [word for word in token_text if word]\n",
        "  return ' '.join(words)"
      ],
      "metadata": {
        "id": "8bwj38lMXxH2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the text by iterating through the line\n",
        "\n",
        "def get_list(data):\n",
        "  list_arr = []\n",
        "  text_to_line = sent_tokenize(data.lower())\n",
        "  for text in text_to_line:\n",
        "    clean_line = remove(text)\n",
        "    list_arr.append(clean_line)\n",
        "  return list_arr"
      ],
      "metadata": {
        "id": "ChBGxFqaShoF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the text array of all files\n",
        "\n",
        "def text_list(story_data):\n",
        "  lists = []\n",
        "  for _, row in story_data.iterrows():\n",
        "    text_arr = get_list(row[-4])\n",
        "    lists.append(text_arr)\n",
        "  return lists"
      ],
      "metadata": {
        "id": "SsfV0i0Gsirm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Token of each text\n",
        "\n",
        "def tokenizing(flat_text,text):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(flat_text)\n",
        "  word_index = tokenizer.word_index\n",
        "  tokenid = []\n",
        "  for i in text:\n",
        "    tokens = tokenizer.texts_to_sequences(i)\n",
        "    tokenid.append(tokens)\n",
        "  return tokenid"
      ],
      "metadata": {
        "id": "vR2kRHe6QXzM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the TfidfVectorizer of each text\n",
        "\n",
        "def vecTfid(flat_text,text):\n",
        "  vec = TfidfVectorizer()\n",
        "  vec.fit(flat_text)\n",
        "  vecarr = []\n",
        "  for i in text:\n",
        "    transform = vec.transform(i).toarray()\n",
        "    vecarr.append(transform)\n",
        "  return vecarr"
      ],
      "metadata": {
        "id": "U1pQhvm2QUgC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_values(story_dict, key, values, id):\n",
        "    # Define the fiction and chapter id\n",
        "    fic_id, chap_id = id\n",
        "\n",
        "    # Set the dictionary\n",
        "    story_dict.setdefault(key, {}).setdefault(fic_id, {}).setdefault(chap_id, [])\n",
        "\n",
        "    # Adding the lines into each dictionary keys\n",
        "    for line in values:\n",
        "        if line not in story_dict[key][fic_id][chap_id]:\n",
        "            story_dict[key][fic_id][chap_id].append(line)"
      ],
      "metadata": {
        "id": "1rkAngFFmAku"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the flag system to count copy-pasted and high similarity line\n",
        "\n",
        "def count_flag(token1, token2, tf1, tf2, story_dict, text1, text2, title):\n",
        "  # Defining all necessary flag variables\n",
        "  plag_tf_token = 0\n",
        "  di = len(tf1)\n",
        "  token_cos = []\n",
        "  cp = 0\n",
        "  hs = 0\n",
        "\n",
        "  # Getting the similarity on Tokenized text and Vectorized text\n",
        "  tf_cos = cosine_similarity(tf1,tf2)\n",
        "  for i in range(len(token1)):\n",
        "    cos_line= []\n",
        "    for j in range(len(token2)):\n",
        "      length = len(list(set(token1[i]+token2[j])))\n",
        "      cos = len(set(token1[i])&set(token2[j]))/length\n",
        "      cos_line.append(cos)\n",
        "    token_cos.append(cos_line)\n",
        "\n",
        "  \"\"\"\n",
        "  Both Tokenized and Vectorized has their own strength and uses\n",
        "  Similarity threshold (0.9999, 0.7, and 0.35) may be changed\n",
        "  Flag system works by:\n",
        "    1. Flag each line that are copy-pasted or high similarity with value 1, final result is the total line\n",
        "    2. Line with less than 0.9999 similarity uses several threshold (0.7 and 0.3)\n",
        "          - Both threshold gave different flag value (for tf) (plag_tf_token)\n",
        "          - Final result of plag_tf_token is the summation of flag tf and token if total > 1\n",
        "  \"\"\"\n",
        "  for i in range(di):\n",
        "    tf = 0\n",
        "    token = 0\n",
        "    #print(tf_cos[i])\n",
        "    #print(token_cos[i])\n",
        "    # For high similarity checking\n",
        "    if any(vals >= 0.9999 for vals in tf_cos[i]):\n",
        "      tryis = [index for index, vals in enumerate(tf_cos[i]) if vals >= 0.9999]\n",
        "      add_values(story_dict, text1[i],[text2[i] for i in tryis], title)\n",
        "      hs+=1\n",
        "    elif any(0.35 < vals < 0.9999 for vals in tf_cos[i]):\n",
        "      tryis = [index for index, vals in enumerate(tf_cos[i]) if 0.35 < vals < 0.9999]\n",
        "      add_values(story_dict, text1[i],[text2[i] for i in tryis], title)\n",
        "      tf = 1\n",
        "    else:\n",
        "      tf = 0\n",
        "\n",
        "    # For high structure similarity checking\n",
        "    if any(vals >= 0.9999 for vals in token_cos[i]):\n",
        "      tryis = [index for index, vals in enumerate(token_cos[i]) if vals >= 0.9999]\n",
        "      add_values(story_dict, text1[i],[text2[i] for i in tryis], title)\n",
        "      cp+=1\n",
        "    elif any(0.7 < vals < 0.9999 for vals in token_cos[i]):\n",
        "      tryis = [index for index, vals in enumerate(token_cos[i]) if 0.7 < vals < 0.9999]\n",
        "      add_values(story_dict, text1[i],[text2[i] for i in tryis], title)\n",
        "      token = 1\n",
        "    else:\n",
        "      token = 0\n",
        "\n",
        "    # For plagiarism checking score (other than copy-pasted or 99% similarity)\n",
        "    if token + tf > 1:\n",
        "      plag_tf_token += 1\n",
        "  return plag_tf_token, di, hs, cp"
      ],
      "metadata": {
        "id": "7MkLbZBtQYc9"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main code of the system, calling all the neccesary functions\n",
        "def main_code(story_data,text_list):\n",
        "  # Flattened the text to smooth out the tokenize and vectorize\n",
        "  flat_text = [line for text in text_list for line in text]\n",
        "\n",
        "  # Calling the tokenizer and vectorizer function\n",
        "  tfid = vecTfid(flat_text,text_list)\n",
        "  token = tokenizing(flat_text,text_list)\n",
        "\n",
        "  plag_score = 0\n",
        "  fin_plag_score = 0\n",
        "  verdict = \"\"\n",
        "  YN = 0\n",
        "  story_dict = {}\n",
        "\n",
        "  # Iterating each text to examine the similarity between text\n",
        "  for j in range(len(token)):\n",
        "    # Skip chapter text of same story\n",
        "    if story_data.iloc[-1,1] != story_data.iloc[j,1]:\n",
        "      plag_ft, di, hs, cp = count_flag(token[-1], token[j], tfid[-1], tfid[j], story_dict, text_list[-1], text_list[j], story_data.iloc[j,1:3])\n",
        "      plag_score = (plag_ft+(hs+cp)/2)/di\n",
        "    if plag_score > fin_plag_score:\n",
        "      fin_plag_score = plag_score\n",
        "\n",
        "  if fin_plag_score >= 0.3:\n",
        "    YN = 1\n",
        "    verdict = \"Unfortunately, your plagiarism score has exceeded the maximum percentage. Please revise and try again.\"\n",
        "  else:\n",
        "    YN = 0\n",
        "    verdict = \"Congratulations, your plagiarism score is within safe percentage! You may upload your work!\"\n",
        "\n",
        "  final = pd.DataFrame({'Final Plagiarism Score': [fin_plag_score*100], 'Y/N': YN, 'Verdict': verdict})\n",
        "\n",
        "  if len(story_dict) == 0:\n",
        "    add_values(story_dict, '-', '-', ['-', '-'])\n",
        "\n",
        "  data = [{'Line': key, 'Fiction_id': fic_id, 'Chapter_id': chap_id, 'Similar Line': value}\n",
        "        for key, file_dict in story_dict.items()\n",
        "        for fic_id, chap_dict in file_dict.items()\n",
        "        for chap_id, value in chap_dict.items()]\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  df_e = df.explode('Similar Line')\n",
        "  df_e.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  return final.to_json(), df_e.to_json()"
      ],
      "metadata": {
        "id": "0DcqkAr2dHCz"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Plagiarism_Checker(story_data):\n",
        "  story_url='https://readscape.live/pdftodatabase'\n",
        "  text = text_list(story_data)\n",
        "  show_arr = main_code(story_data,text)\n",
        "  response = requests.post(story_url, data=[show_arr])\n",
        "  if response.status_code == 200:\n",
        "    print(response.json)\n",
        "  return show_arr"
      ],
      "metadata": {
        "id": "hHdijRDPr8KU"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def request(story_url='https://readscape.live/pdftodatabase'):\n",
        "  story = requests.get(story_url)\n",
        "  story = story.json()\n",
        "  story = pd.DataFrame(story['data'])\n",
        "  return story"
      ],
      "metadata": {
        "id": "jO87oakFNmSt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final, df_e= Plagiarism_Checker(request())\n",
        "df_e"
      ],
      "metadata": {
        "id": "69EMwLQvfEKZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "712fb094-fd06-453d-9507-179599b72092"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Response.json of <Response [200]>>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Line\":{\"0\":\"-\"},\"Fiction_id\":{\"0\":\"-\"},\"Chapter_id\":{\"0\":\"-\"},\"Similar Line\":{\"0\":\"-\"}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final"
      ],
      "metadata": {
        "id": "JcxETRTg3O9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "51373452-72e8-432e-e7ed-2831162a1dac"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Final Plagiarism Score\":{\"0\":0},\"Y\\\\/N\":{\"0\":0},\"Verdict\":{\"0\":\"Congratulations, your plagiarism score is within safe percentage! You may upload your work!\"}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(final)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "CSzRRvnj3mMD",
        "outputId": "439a3553-cb91-46e2-f6eb-e3695bc2ae2d"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Final Plagiarism Score  Y/N  \\\n",
              "0                       0    0   \n",
              "\n",
              "                                             Verdict  \n",
              "0  Congratulations, your plagiarism score is with...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-397ee761-a8f9-4bea-bcf6-5b57f2942964\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Final Plagiarism Score</th>\n",
              "      <th>Y/N</th>\n",
              "      <th>Verdict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Congratulations, your plagiarism score is with...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-397ee761-a8f9-4bea-bcf6-5b57f2942964')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-397ee761-a8f9-4bea-bcf6-5b57f2942964 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-397ee761-a8f9-4bea-bcf6-5b57f2942964');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwY0BlEf7WxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}